# configs/unlearning/gradasc.yaml

unlearning:
  epochs: 1
  batch_size: 64         # Should be the same as training batch size for consistency
  learning_rate: 0.01
  optimizer: SGD
  momentum: 0.9          # Common for SGD-based methods
  weight_decay: 0.0